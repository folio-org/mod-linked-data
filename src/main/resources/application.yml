spring:
  application:
    name: mod-linked-data
  cloud:
    openfeign:
      okhttp:
        enabled: true
  datasource:
    username: ${DB_USERNAME:postgres}
    password: ${DB_PASSWORD:postgres}
    url: jdbc:postgresql://${DB_HOST:postgres}:${DB_PORT:5432}/${DB_DATABASE:okapi_modules}
  liquibase:
    change-log: classpath:changelog/changelog-master.xml
  main:
    allow-bean-definition-overriding: true
  jpa:
    hibernate:
      ddl-auto: none
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        event:
          merge:
            entity_copy_observer: allow
    open-in-view: false
  kafka:
    bootstrap-servers: ${KAFKA_HOST:kafka}:${KAFKA_PORT:9092}
    consumer:
      max-poll-records: ${KAFKA_CONSUMER_MAX_POLL_RECORDS:200}
    security:
      protocol: ${KAFKA_SECURITY_PROTOCOL:PLAINTEXT}
    ssl:
      key-store-password: ${KAFKA_SSL_KEYSTORE_PASSWORD:}
      key-store-location: ${KAFKA_SSL_KEYSTORE_LOCATION:}
      trust-store-password: ${KAFKA_SSL_TRUSTSTORE_PASSWORD:}
      trust-store-location: ${KAFKA_SSL_TRUSTSTORE_LOCATION:}
    producer:
      acks: all
      properties:
        enable.idempotence: true
        max.in.flight.requests.per.connection: 5
        retries: 5
        spring.json.add.type.headers: false

folio:
  environment: ${ENV:folio}
  okapiUrl: ${okapi.url}
  tenant:
    validation:
      enabled: true
  logging:
    request:
      enabled: true
    feign:
      enabled: true
  retry:
    enabled: true
  kafka:
    listener:
      source-record-domain-event:
        concurrency: ${KAFKA_SOURCE_RECORD_DOMAIN_EVENT_CONCURRENCY:1}
        topic-pattern: ${KAFKA_SOURCE_RECORD_DOMAIN_EVENT_TOPIC_PATTERN:(${folio.environment}\.)(.*\.)srs.source_records}
        group-id: ${folio.environment}-linked-data-source-record-domain-event-group
      inventory-instance-event:
        concurrency: ${KAFKA_INVENTORY_INSTANCE_EVENT_CONCURRENCY:1}
        topic-pattern: ${KAFKA_INVENTORY_INSTANCE_EVENT_TOPIC_PATTERN:(${folio.environment}\.)(.*\.)inventory.instance}
        group-id: ${folio.environment}-linked-data-inventory-instance-event-group
      ld-import-output-event:
        concurrency: ${KAFKA_LD_IMPORT_OUTPUT_EVENT_CONCURRENCY:10}
        topic-pattern: ${KAFKA_LD_IMPORT_OUTPUT_EVENT_TOPIC_PATTERN:(${folio.environment}\.)(.*\.)linked_data_import.output}
        group-id: ${folio.environment}-linked-data-import-output-event-group
    retry-interval-ms: ${KAFKA_RETRY_INTERVAL_MS:2000}
    retry-delivery-attempts: ${KAFKA_RETRY_DELIVERY_ATTEMPTS:6}
    topics:
      - name: ${mod-linked-data.kafka.topic.work-search-index}
        numPartitions: ${KAFKA_WORK_SEARCH_INDEX_TOPIC_PARTITIONS:3}
        replicationFactor: ${KAFKA_WORK_SEARCH_INDEX_TOPIC_REPLICATION_FACTOR:}
      - name: ${mod-linked-data.kafka.topic.hub-search-index}
        numPartitions: ${KAFKA_HUB_SEARCH_INDEX_TOPIC_PARTITIONS:3}
        replicationFactor: ${KAFKA_HUB_SEARCH_INDEX_TOPIC_REPLICATION_FACTOR:}

mod-linked-data:
  reindex:
    page-size: 1000
  search:
    max-params: ${SEARCH_MAX_PARAMS:100}
  kafka:
    topic:
      work-search-index: ${KAFKA_WORK_SEARCH_INDEX_TOPIC:linked-data.work}
      hub-search-index: ${KAFKA_HUB_SEARCH_INDEX_TOPIC:linked-data.hub}
      instance-ingress: ${KAFKA_INVENTORY_INSTANCE_INGRESS_EVENT_TOPIC:inventory.instance_ingress}
      linked-data-import-result: ${KAFKA_LINKED_DATA_IMPORT_RESULT_TOPIC:linked_data_import.result}
  cache:
    ttl:
      spec-rules: ${CACHE_TTL_SPEC_RULES_MS:18000000}
      settings-entries: ${CACHE_TTL_SETTINGS_ENTRIES_MS:18000000}
      module-state: ${CACHE_TTL_MODULE_STATE_MS:18000000}

management:
  endpoints:
    web:
      exposure:
        include: info,health,liquibase,threaddump,heapdump,loggers,env,httptrace,metrics,prometheus
      base-path: /admin
  endpoint:
    loggers:
      access: unrestricted
  influx:
    metrics:
      export:
        enabled: false

server:
  port: ${SERVER_PORT:8081}
